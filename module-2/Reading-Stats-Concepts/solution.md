# Difference between expected value & mean
The concept of expectation value or expected value may be understood from the following example. Let ğ‘‹
represent the outcome of a roll of an unbiased six-sided die. The possible values for ğ‘‹
are 1, 2, 3, 4, 5, and 6, each having the probability of occurrence of 1/6. 

The expectation value (or expected value) of ğ‘‹ is then given by  
#### (ğ‘‹)expected=1(1/6)+2â‹…(1/6)+3â‹…(1/6)+4â‹…(1/6)+5â‹…(1/6)+6â‹…(1/6)=21/6=3.5

Suppose that in a sequence of ten rolls of the die, if the outcomes are 5, 2, 6, 2, 2, 1, 2, 3, 6, 1, then the average (arithmetic mean) of the results is given by
#### (ğ‘‹)average=(5+2+6+2+2+1+2+3+6+1)/10=3.0

We say that the average value is 3.0, with the distance of 0.5 from the ex
pectation value of 3.5. If we roll the die ğ‘ times, where ğ‘ is very large, then the average will converge to the expected value, i.e.,(ğ‘‹)average=(ğ‘‹)expected. 

This is evidently because, when ğ‘ is very large each possible value of ğ‘‹ (i.e. 1 to 6) will occur with equal probability of 1/6, turning the average to the expectation value


# What is the "problem" in science with p-values?

There is nothing inherently wrong with p-values. They are a valuable tool to help us understand the significance of our evidence. However, overreliance on a single metric or a single study to support broader hypotheses is dangerous. Consumers of such research must keep a broader perspective, and media outlets must refrain from sensationalizing the results of any individual study. Ultimately, p-values are useful tools, but it is up to us to make sure we are using that tool properly.

https://towardsdatascience.com/the-problem-with-p-values-f056245f78a3

# Applying testing to a specific case: A/B testing.
The question asked is very unclear for this topic. 
However to do A/B testing it is important to have a clear control group and test group 
Create a h0 and h1 hypothesis
Gather the right data 
Compare the distributions of the two groups 
Test hypothesis 