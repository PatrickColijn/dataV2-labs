{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n",
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "for element in (X, y):\n",
    "    print(element.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.  16.  29. 154. 254. 243. 135.  25.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  19.  57. 166. 253. 253. 253. 254. 235.  38.  51.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. 173. 253. 254. 253. 187. 168. 169.  93.  41.  48.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  76. 223. 253. 242. 116.   6.   0.   0.   0.  98.  78.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  26.  92.\n",
      " 217. 254. 229. 102.   0.   0.   0.   0.   7.  19.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 150. 254.\n",
      " 253. 196.   9.   0.   0.   0.   0.   0.  19. 163. 120.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 154. 223. 254.\n",
      " 171.  37.   0.   0.   0.   0.   0.   0.  45. 216. 165.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 247. 253. 229.\n",
      "   9.   0.   0.   0.   0.   0.   0.   0. 157. 253.  90.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  13. 105. 254. 245. 176.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 105. 248. 150.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  89. 254. 241. 169.  13.   0.\n",
      "   0.   0.   0.   0.   0.   0.  51. 254. 197.  76.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  29. 235. 254. 184.  25.   0.   0.\n",
      "   0.   0.   0.   0.   0.  29. 235. 254. 134.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  98. 241. 242.  98.   0.   0.   0.\n",
      "   0.   0.   0.   0.  26. 123. 241. 242.  98.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  83. 230. 254. 114.   0.   0.   0.   0.\n",
      "   0.   0.   0.  13. 157. 254. 204. 114.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  19. 188. 253. 152.  38.   0.   0.   0.   0.\n",
      "   0.   0.  26. 170. 226. 209.  97.  38.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 129. 253. 165.  16.   0.   0.   0.   0.   0.\n",
      "   0.  67. 223. 254. 209.  13.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 180. 228.  52.   3.   0.   0.   0.   0.   0.\n",
      " 102. 235. 253. 128.  22.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  92. 254. 120.   0.   0.   0.   0.  26. 205.\n",
      " 254. 245. 176.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 117. 253. 225. 120.  57. 132. 169. 244. 254.\n",
      " 215.  81.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   7. 188. 253. 253. 254. 253. 253. 215. 156.\n",
      "  19.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  95. 229. 253. 255. 177.  52.  16.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "\n",
      "Y:  0\n",
      "X:  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.  16.  29. 154. 254. 243. 135.  25.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  19.  57. 166. 253. 253. 253. 254. 235.  38.  51.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. 173. 253. 254. 253. 187. 168. 169.  93.  41.  48.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  76. 223. 253. 242. 116.   6.   0.   0.   0.  98.  78.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  26.  92.\n",
      " 217. 254. 229. 102.   0.   0.   0.   0.   7.  19.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 150. 254.\n",
      " 253. 196.   9.   0.   0.   0.   0.   0.  19. 163. 120.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 154. 223. 254.\n",
      " 171.  37.   0.   0.   0.   0.   0.   0.  45. 216. 165.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 247. 253. 229.\n",
      "   9.   0.   0.   0.   0.   0.   0.   0. 157. 253.  90.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  13. 105. 254. 245. 176.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 105. 248. 150.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  89. 254. 241. 169.  13.   0.\n",
      "   0.   0.   0.   0.   0.   0.  51. 254. 197.  76.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  29. 235. 254. 184.  25.   0.   0.\n",
      "   0.   0.   0.   0.   0.  29. 235. 254. 134.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  98. 241. 242.  98.   0.   0.   0.\n",
      "   0.   0.   0.   0.  26. 123. 241. 242.  98.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  83. 230. 254. 114.   0.   0.   0.   0.\n",
      "   0.   0.   0.  13. 157. 254. 204. 114.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  19. 188. 253. 152.  38.   0.   0.   0.   0.\n",
      "   0.   0.  26. 170. 226. 209.  97.  38.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 129. 253. 165.  16.   0.   0.   0.   0.   0.\n",
      "   0.  67. 223. 254. 209.  13.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 180. 228.  52.   3.   0.   0.   0.   0.   0.\n",
      " 102. 235. 253. 128.  22.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.  92. 254. 120.   0.   0.   0.   0.  26. 205.\n",
      " 254. 245. 176.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. 117. 253. 225. 120.  57. 132. 169. 244. 254.\n",
      " 215.  81.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   7. 188. 253. 253. 254. 253. 253. 215. 156.\n",
      "  19.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  95. 229. 253. 255. 177.  52.  16.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      "\n",
      "Y:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"X: \", X[35999])\n",
    "print(\"\")\n",
    "print(\"Y: \",y[35999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1380ecfd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1380ecfd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOw0lEQVR4nO3df6xU9ZnH8c+ztBgiGBRuCFqzdIvR6MZSnJBVTGVDtkGCIDEhoKnUX1eDhBL7x5L6AxINIWYtrmYlAcSiVkkTKhI03V6RxPCHDYOwipIF11zDjwtcMIaLf8BKn/3jHrq3eOc7l5kzc+byvF/JZGbOM+eeJ0c+npnznTlfc3cBuPj9XdENAGgOwg4EQdiBIAg7EARhB4L4XjM3Nnr0aB83blwzNwmE0tnZqePHj1t/tbrCbmbTJP27pCGS1rr7itTrx40bp3K5XM8mASSUSqWKtZrfxpvZEEn/Iel2SddLmmdm19f69wA0Vj2f2SdJ+tzdv3D3M5I2SJqVT1sA8lZP2K+SdKDP84PZsr9hZu1mVjazcnd3dx2bA1CPhp+Nd/fV7l5y91JbW1ujNweggnrCfkjS1X2e/yBbBqAF1RP2HZKuMbMfmtlQSXMlbc6nLQB5q3nozd2/NbOFkv5TvUNv69z909w6A5CrusbZ3f1dSe/m1AuABuLrskAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0dQpm4G+vv7662S9p6cnWX/66aeT9TVr1lSsDR8+PLnuwoULk/VFixYl62PHjk3Wi8CRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJwddTlx4kSyvm/fvoq1F198Mbnuhg0baurpHDOrWDt16lRy3bVr1ybr9913X7J++PDhZP2mm25K1huhrrCbWaekHklnJX3r7qU8mgKQvzyO7P/s7sdz+DsAGojP7EAQ9YbdJf3JzHaaWXt/LzCzdjMrm1m5u7u7zs0BqFW9Yb/V3SdKul3So2b20/Nf4O6r3b3k7qW2trY6NwegVnWF3d0PZffHJL0laVIeTQHIX81hN7NLzWzEuceSfiZpT16NAchXPWfjx0h6KxvL/J6kN9z9j7l0hUHjoYceStY3bdpUsebuyXVT4+SSNHXq1GR91KhRNW97xowZyfrZs2eT9SFDhiTrRag57O7+haQf59gLgAZi6A0IgrADQRB2IAjCDgRB2IEg+IkrkrZs2ZKs79q1q+a/PWLEiGT9qaeeStarXc556NChF9zTQK1bty5ZHz16dLI+YcKEPNsZEI7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+wXuWqXNH7//feT9WrTInd2dibrqamLly1blly3vb3fK501xenTp5P1WbNmJeupn9cWhSM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOPtF7plnnknWV61alaxXu5zz5MmTk/WOjo6KtWHDhiXXLVK1KZ0XL16crN9www3J+pIlSy64p3pxZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnvwikfvedGuceiLvuuitZX758ebLeymPpKdWuA7Bjx45kvdqUzkWoemQ3s3VmdszM9vRZdoWZdZjZ/uz+8sa2CaBeA3kb/1tJ085btkTSVne/RtLW7DmAFlY17O7+gaSvzls8S9L67PF6SXfm3BeAnNV6gm6Mu3dlj49IGlPphWbWbmZlMyt3d3fXuDkA9ar7bLy7uyRP1Fe7e8ndS21tbfVuDkCNag37UTMbK0nZ/bH8WgLQCLWGfbOk+dnj+ZLezqcdAI1SdZzdzN6UNEXSaDM7KGmppBWSfm9mD0j6UtKcRjYZ3c6dO5P11157rWKt2vXPU9d1l6RXX301WR+s4+jVrFy5Mlnft29fsl5tbvkiVA27u8+rUJqacy8AGoivywJBEHYgCMIOBEHYgSAIOxAEP3Ftgp6enmT99ddfT9YXLFiQrKeGv2bOnJlcd9OmTcn6xaraJbTfeOONZP2RRx5J1u++++4L7qnROLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMszfBli1bkvVq4+iXXXZZsj5t2vnXA/1/a9euTa57MUv9NLjaPr/55puT9enTp9fUU5E4sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyz5+DAgQPJ+qJFi+r6+9XGfJ9//vmKtREjRtS17VZWbb+nvn9QzZQpU5L1GTNm1Py3i8KRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJw9Bx0dHcn6mTNnkvVqY+Fz5qRnxK427fJgdfjw4WR9/fr1yXpqv1fb5+PHj0/WB6OqR3YzW2dmx8xsT59ly8zskJntzm6D75f8QDADeRv/W0n9fRVppbtPyG7v5tsWgLxVDbu7fyDpqyb0AqCB6jlBt9DMPs7e5l9e6UVm1m5mZTMrd3d317E5APWoNeyrJP1I0gRJXZKeq/RCd1/t7iV3L7W1tdW4OQD1qins7n7U3c+6+18krZE0Kd+2AOStprCbWd+xntmS9lR6LYDWUHWc3czelDRF0mgzOyhpqaQpZjZBkkvqlPRwA3tsCRs3bqxYe/zxx5Prnjx5Mll/7rmKn4IkSffff3+yPlhVm7f+iSeeSNZfeeWVZH3ixIkVa/fcc09y3Ytxn1cNu7vP62fxyw3oBUAD8XVZIAjCDgRB2IEgCDsQBGEHguAnrpkTJ04k6y+99FLF2tGjR5PrPvxwemRyMF6WeKBSP1NdvHhxct0PP/wwWb/xxhuT9YULF1asTZ48ObnuxYgjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTh75oUXXkjWt23bVrE2d+7c5LorVqxI1keOHJmst7KtW7cm6w8++GDFWmdnZ3LdauPo27dvT9Yv5umqa8GRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJw9s3PnzmT9yiuvrFh77LHHkusO5vHe1atXJ+vVLqOduk7A0qVLk+suWLAgWR/M+7UIHNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2TPVfpP+zjvvVKy99957yXVLpVJNPeUhdd12qfo163ft2pWsDxs2LFmfOXNmxdqyZcuS6yJfVY/sZna1mW0zs8/M7FMz+2W2/Aoz6zCz/dn95Y1vF0CtBvI2/ltJv3L36yX9k6RHzex6SUskbXX3ayRtzZ4DaFFVw+7uXe7+Ufa4R9JeSVdJmiVpffay9ZLubFSTAOp3QSfozGycpJ9I+rOkMe7elZWOSBpTYZ12MyubWbm7u7uOVgHUY8BhN7PhkjZKWuzuJ/vW3N0leX/ruftqdy+5e6mtra2uZgHUbkBhN7Pvqzfov3P3P2SLj5rZ2Kw+VtKxxrQIIA9Vh97MzCS9LGmvu/+mT2mzpPmSVmT3bzekwybp6upK1nt3Q/9WrVpV17Zvu+22ZD017CdJ+/fvr3ndb775Jlm/7rrrkvXly5cn67Nnz07W0TwDGWefLOnnkj4xs93Zsl+rN+S/N7MHJH0paU5jWgSQh6phd/ftkiod1qbm2w6ARuHrskAQhB0IgrADQRB2IAjCDgRhvV9+a45SqeTlcrlp27sQp0+fTtanT59esZaaznkgqv03SI3xV3Pttdcm67fcckuy/uyzzybro0aNuuCe0DilUknlcrnffzAc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCC4lnbnkkkuS9Xvvvbdibe/evcl1jxw5UlNP59xxxx3J+pNPPlmxNn78+OS6I0eOrKknDD4c2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZB2j+/Pk11YBWwZEdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4KoGnYzu9rMtpnZZ2b2qZn9Mlu+zMwOmdnu7Fb5wuoACjeQL9V8K+lX7v6RmY2QtNPMOrLaSnf/t8a1ByAvA5mfvUtSV/a4x8z2Srqq0Y0ByNcFfWY3s3GSfiLpz9mihWb2sZmtM7PLK6zTbmZlMyt3d3fX1SyA2g047GY2XNJGSYvd/aSkVZJ+JGmCeo/8z/W3nruvdveSu5fa2tpyaBlALQYUdjP7vnqD/jt3/4MkuftRdz/r7n+RtEbSpMa1CaBeAzkbb5JelrTX3X/TZ/nYPi+bLWlP/u0ByMtAzsZPlvRzSZ+Y2e5s2a8lzTOzCZJcUqekhxvSIYBcDORs/HZJ/c33/G7+7QBoFL5BBwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCMLcvXkbM+uW9GWfRaMlHW9aAxemVXtr1b4keqtVnr39vbv3e/23pob9Oxs3K7t7qbAGElq1t1btS6K3WjWrN97GA0EQdiCIosO+uuDtp7Rqb63al0RvtWpKb4V+ZgfQPEUf2QE0CWEHgigk7GY2zcz+28w+N7MlRfRQiZl1mtkn2TTU5YJ7WWdmx8xsT59lV5hZh5ntz+77nWOvoN5aYhrvxDTjhe67oqc/b/pndjMbImmfpH+RdFDSDknz3P2zpjZSgZl1Siq5e+FfwDCzn0o6JelVd//HbNmzkr5y9xXZ/ygvd/d/bZHelkk6VfQ03tlsRWP7TjMu6U5Jv1CB+y7R1xw1Yb8VcWSfJOlzd//C3c9I2iBpVgF9tDx3/0DSV+ctniVpffZ4vXr/sTRdhd5agrt3uftH2eMeSeemGS903yX6aooiwn6VpAN9nh9Ua8337pL+ZGY7zay96Gb6Mcbdu7LHRySNKbKZflSdxruZzptmvGX2XS3Tn9eLE3Tfdau7T5R0u6RHs7erLcl7P4O10tjpgKbxbpZ+phn/qyL3Xa3Tn9eriLAfknR1n+c/yJa1BHc/lN0fk/SWWm8q6qPnZtDN7o8V3M9ftdI03v1NM64W2HdFTn9eRNh3SLrGzH5oZkMlzZW0uYA+vsPMLs1OnMjMLpX0M7XeVNSbJc3PHs+X9HaBvfyNVpnGu9I04yp43xU+/bm7N/0mabp6z8j/j6THi+ihQl//IOm/stunRfcm6U31vq37X/We23hA0ihJWyXtl/SepCtaqLfXJH0i6WP1BmtsQb3dqt636B9L2p3dphe97xJ9NWW/8XVZIAhO0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8H/2px6iyMCnUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import libraries \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "plt.imshow(X[35999].reshape(28,28), cmap = plt.cm.binary, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  0\n",
      "Y:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Y: \",y[35999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:6000]\n",
    "y_train = y[:6000]\n",
    "\n",
    "X_test = X[6000:]\n",
    "y_test = y[6000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = np.where(y_train == '5',1,0)\n",
    "y_test_5 = np.where(y_test == '5',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcount= y_train_5\n",
    "ycount= y_test_5\n",
    "\n",
    "unique, counts = np.unique(xcount, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "unique, counts = np.unique(ycount, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit/train the data \n",
    "logreg.fit(X_train, y_train_5)\n",
    "\n",
    "# Predict values \n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test_5)))\n",
    "print(\"\")\n",
    "\n",
    "# Create confusion matrix to assess model\n",
    "confusion_matrix = confusion_matrix(y_test_5, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Compute the precision of the model\n",
    "print(classification_report(y_test_5, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/train the data \n",
    "never_5_clf.fit(X_train)\n",
    "\n",
    "# Predict values \n",
    "y_pred_never_5 = never_5_clf.predict(X_test)\n",
    "\n",
    "# Create confusion matrix to assess model\n",
    "confusion_matrix_never_5 = confusion_matrix(y_test_5, \n",
    "                                    y_pred_never_5)\n",
    "print(confusion_matrix_never_5)\n",
    "print(\"\")\n",
    "\n",
    "# Compute the precision of the model\n",
    "print(classification_report_never_5(y_test_5, y_pred_never_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_pred_never_5))\n",
    "print(y_pred_never_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
